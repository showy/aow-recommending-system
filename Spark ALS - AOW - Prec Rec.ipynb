
import org.apache.spark.sql.functions.{min, max}
import org.apache.spark.ml.recommendation.{ALS, ALSModel}
import scala.util.Random
import org.apache.spark.sql.functions.lit
import org.apache.spark.sql.{Dataset, Row}
import org.apache.spark.sql.functions._
import org.apache.spark.storage.StorageLevel._
import scala.collection.mutable
import org.apache.spark.sql.functions.udf
import org.apache.spark.sql.functions._

case class Rating(movie: Int, rating: Float)

val trainFile = "../datasets/AOW-private/train_AOW_positive_only_cleaned.csv"
val testFile = "../datasets/AOW-private/test_AOW_positive_only_cleaned.csv"
val columns = Array("user", "movie", "rating")

val train = spark.read.options(Map("header" -> "true", "inferSchema" -> "true", "delimiter" -> ",")).csv(trainFile).toDF(columns: _*)
val test = spark.read.options(Map("header" -> "true", "inferSchema" -> "true", "delimiter" -> ",")).csv(testFile).toDF(columns: _*)

import train.sparkSession.implicits._

val model = new ALS()
    .setUserCol("user")
    .setItemCol("movie")
    .setRatingCol("rating")
    .setPredictionCol("prediction")
    .setImplicitPrefs(true)
    .fit(train)

model.setColdStartStrategy("drop")

val recommendations = model.recommendForAllUsers(1680)

val moviesByUser = mutable.Map[Int, List[Int]]()


val watchedMovies = udf { (user: Int, movie: Int) =>
    moviesByUser.update(user, movie :: moviesByUser.getOrElse(user, Nil))
    moviesByUser.get(user).get
}

val usersWithItems = train
    .withColumn("watchedMovies", watchedMovies($"user", $"movie"))
    .withColumn("countWatched", size($"watchedMovies"))
    .sort(desc("countWatched"))
    .select("user", "watchedMovies")
    .dropDuplicates("user")

val fullUsersDF = recommendations.join(usersWithItems, Array("user"), "inner")

val topN = udf { (movies: Seq[Int], ratings: Seq[Float], watched: Seq[Int], n: Int) =>
  movies
    .zip(ratings)
    .filter { case (movie, _) => !watched.contains(movie) }
    .sortBy { case(_, rating) => rating }
    .reverse
    .take(n)
    .map { case(movie, rating) => Rating(movie, rating) }
}

val usersTopRecommendations = fullUsersDF
  .select("user", "recommendations.movie", "recommendations.rating", "watchedMovies")
  .withColumn("topN", topN($"movie", $"rating", $"watchedMovies", lit(10)))
  .select("user", "topN")


val testUsersWithItems = test
    .withColumn("watchedMovies", watchedMovies($"user", $"movie"))
    .withColumn("countWatched", size($"watchedMovies"))
    .sort(desc("countWatched"))
    .select("user", "watchedMovies")
    .dropDuplicates("user")

val usersForPrecision = usersTopRecommendations.join(testUsersWithItems, Array("user"), "inner")

val computePrecision = udf { (movies: Seq[Int], ratings: Seq[Float], watched: Seq[Int]) =>
  movies.foldRight(0)( (m, sum) => if (watched.contains(m)) sum + 1 else sum) / movies.size.toDouble
}

val usersWithPrec = usersForPrecision
  .select("user", "topN.movie", "topN.rating", "watchedMovies")
  .withColumn("precision", computePrecision($"movie", $"rating", $"watchedMovies"))
  .persist(DISK_ONLY)

usersWithPrec.agg(sum($"precision")).first.getDouble(0) / usersWithPrec.count
