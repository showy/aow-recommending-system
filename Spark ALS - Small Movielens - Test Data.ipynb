{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.{min, max}\n",
    "import org.apache.spark.ml.recommendation.{ALS, ALSModel}\n",
    "import scala.util.Random\n",
    "import org.apache.spark.sql.functions.lit\n",
    "import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n",
    "import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.rdd.RDD\n",
    "import org.apache.spark.sql.{Dataset, Row}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ratingsTrain = ../datasets/ua.base\n",
       "ratingsTest = ../datasets/ua.test\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../datasets/ua.test"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ratingsTrain = \"../datasets/ua.base\"\n",
    "val ratingsTest = \"../datasets/ua.test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "colNames = Array(userId, movieId, rating, ts)\n",
       "dfTrain = [userId: int, movieId: int ... 2 more fields]\n",
       "dfTest = [userId: int, movieId: int ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[userId: int, movieId: int ... 2 more fields]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val colNames = Array(\"userId\", \"movieId\", \"rating\", \"ts\")\n",
    "val dfTrain = spark.read.options(Map(\"header\" -> \"false\", \"inferSchema\" -> \"true\", \"sep\" -> \"\\t\")).csv(ratingsTrain).toDF(colNames: _*)\n",
    "val dfTest = spark.read.options(Map(\"header\" -> \"false\", \"inferSchema\" -> \"true\", \"sep\" -> \"\\t\")).csv(ratingsTest).toDF(colNames: _*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ranks = List(10, 20)\n",
       "regParams = List(1.0, 0.001)\n",
       "alphas = List(1.0, 0.001)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "List(1.0, 0.001)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ranks = Seq(10, 20)\n",
    "val regParams = Seq(1, 0.001)\n",
    "val alphas = Seq(1, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alsModels = List((Map(rank -> 10, regParam -> 1.0, alpha -> 1.0),als_e5770c05bf42), (Map(rank -> 10, regParam -> 1.0, alpha -> 0.001),als_bb3ca58ca8af), (Map(rank -> 10, regParam -> 0.001, alpha -> 1.0),als_b010de0eed11), (Map(rank -> 10, regParam -> 0.001, alpha -> 0.001),als_9c55277f2950), (Map(rank -> 20, regParam -> 1.0, alpha -> 1.0),als_dc40fd4edac1), (Map(rank -> 20, regParam -> 1.0, alpha -> 0.001),als_153792232371), (Map(rank -> 20, regParam -> 0.001, alpha -> 1.0),als_4fc95f3f0123), (Map(rank -> 20, regParam -> 0.001, alpha -> 0.001),als_00a6e7a6bd25))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "List((Map(rank -> 10, regParam -> 1.0, alpha -> 1.0),als_e5770c05bf42), (Map(rank -> 10, regParam -> 1.0, alpha -> 0.001),als_bb3ca58ca8af), (Map(rank -> 10, regParam -> 0.001, alpha -> 1.0),als_b010de0eed11), (Map(rank -> 10, regParam -> 0.001, alpha -> 0.001),als_9c55277f2950), (Map(rank -> 20, regParam -> 1.0, alpha -> 1.0),als_dc40fd4edac1), (Map(rank -> 20, regParam -> 1.0, alpha -> 0.001),als_153792232371), (Map(rank -> 20, regParam -> 0.001, alpha -> 1.0),als_4fc95f3f0123), (Map(rank -> 20, regParam -> 0.001, alpha -> 0.001),als_00a6e7a6bd25))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val alsModels = for {\n",
    "    rank <- ranks\n",
    "    regParam <- regParams\n",
    "    alpha <- alphas\n",
    "} yield (Map( \"rank\" -> rank, \"regParam\" -> regParam, \"alpha\" -> alpha), new ALS()\n",
    "            .setRank(rank)\n",
    "            .setUserCol(\"userId\")\n",
    "            .setItemCol(\"movieId\")\n",
    "            .setImplicitPrefs(true)\n",
    "            .fit(dfTrain)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alsModels.foreach { _._2.setColdStartStrategy(\"drop\") }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fullDataset = [userId: int, movieId: int ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[userId: int, movieId: int ... 2 more fields]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fullDataset = dfTrain.union(dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "users = [userId: int]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[userId: int]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val users = fullDataset.select(\"userId\").distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movies = [movieId: int]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[movieId: int]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val movies = fullDataset.select(\"movieId\").distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 5003:=================================>                  (128 + 6) / 200]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "userAndMovies = Array((148,148), (148,471), (148,496), (148,463), (148,833), (148,1088), (148,1238), (148,1342), (148,1580), (148,1591), (148,1645), (148,243), (148,392), (148,540), (148,623), (148,737), (148,858), (148,897), (148,1084), (148,1025), (148,1127), (148,1395), (148,1460), (148,1483), (148,1507), (148,1522), (148,31), (148,516), (148,1139), (148,1143), (148,1270), (148,1303), (148,1322), (148,1339), (148,1352), (148,1618), (148,1650), (148,85), (148,137), (148,251), (148,451), (148,580), (148,808), (148,1265), (148,65), (148,458), (148,879), (148,883), (148,1223), (148,53), (148,255), (148,481), (148,588), (148,799), (148,804), (148,898), (148,970), (148,1157), (148,133), (148,296), (148,472), (148,853), (148,1466), (148,78), (148,322), (148,513), (148,918...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "val userAndMovies = for {\n",
    "    user <- users.collect\n",
    "    movie <- movies.collect\n",
    "} yield (user.getInt(0), movie.getInt(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userAndMoviesDF = [userId: int, movieId: int]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[userId: int, movieId: int]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val userAndMoviesDF = sc.parallelize(userAndMovies).toDF(\"userId\", \"movieId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isPositive = UserDefinedFunction(<function1>,IntegerType,Some(List(IntegerType)))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "UserDefinedFunction(<function1>,IntegerType,Some(List(IntegerType)))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val isPositive = udf { v: Int => if (v >= 0) 1 else 0 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "usersAndMoviesRatingDF = [userId: int, movieId: int ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[userId: int, movieId: int ... 1 more field]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val usersAndMoviesRatingDF = userAndMoviesDF\n",
    "    .join(fullDataset, Seq(\"userId\", \"movieId\"), \"left_outer\")\n",
    "    .drop(\"ts\")\n",
    "    .na\n",
    "    .fill(-1)\n",
    "    .cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "usersAndMoviesFullRatingsDF = [userId: int, movieId: int ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[userId: int, movieId: int ... 1 more field]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val usersAndMoviesFullRatingsDF = usersAndMoviesRatingDF\n",
    "    .withColumn(\"rating\", isPositive($\"rating\"))\n",
    "    .withColumnRenamed(\"rating\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "track_seens: ()org.apache.spark.sql.expressions.UserDefinedFunction\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def track_seens() = {\n",
    "    import scala.collection.mutable\n",
    "    val _seen: mutable.Map[Int, Int] = mutable.Map[Int, Int]()\n",
    "    \n",
    "    udf { (userId: Int) => _seen\n",
    "         .put(userId, _seen.getOrElse(userId, 0) + 1)\n",
    "         .getOrElse(0)\n",
    "    }\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seenCount = UserDefinedFunction(<function1>,IntegerType,Some(List(IntegerType)))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "UserDefinedFunction(<function1>,IntegerType,Some(List(IntegerType)))"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val seenCount = track_seens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "usersAndMoviesFalseInteractions = [userId: int, movieId: int ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[userId: int, movieId: int ... 1 more field]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val usersAndMoviesFalseInteractions = usersAndMoviesFullRatingsDF\n",
    "    .filter($\"label\" === 0)\n",
    "    .withColumn(\"seen\", seenCount($\"userId\"))\n",
    "    .filter($\"seen\" === 0)\n",
    "    .drop(\"seen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = false)\n",
      " |-- movieId: integer (nullable = false)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "usersAndMoviesFalseInteractions.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      " |-- ts: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfTest.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfFullTest = [userId: int, movieId: int ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[userId: int, movieId: int ... 1 more field]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dfFullTest = usersAndMoviesFalseInteractions\n",
    "    .union(\n",
    "        dfTest\n",
    "            .withColumn(\"label\", lit(1))\n",
    "            .select(\"userId\", \"movieId\", \"label\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stage 6897:========================>                               (3 + 4) / 7]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10378"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFullTest.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predictions = List([userId: int, movieId: int ... 3 more fields], [userId: int, movieId: int ... 3 more fields], [userId: int, movieId: int ... 3 more fields], [userId: int, movieId: int ... 3 more fields], [userId: int, movieId: int ... 3 more fields], [userId: int, movieId: int ... 3 more fields], [userId: int, movieId: int ... 3 more fields], [userId: int, movieId: int ... 3 more fields])\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "List([userId: int, movieId: int ... 3 more fields], [userId: int, movieId: int ... 3 more fields], [userId: int, movieId: int ... 3 more fields], [userId: int, movieId: int ... 3 more fields], [userId: int, movieId: int ... 3 more fields], [userId: int, movieId: int ... 3 more fields], [userId: int, movieId: int ... 3 more fields], [userId: int, movieId: int ... 3 more fields])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val predictions = alsModels.map { _._2.transform(dfTest) } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toInt = UserDefinedFunction(<function1>,IntegerType,Some(List(FloatType)))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "UserDefinedFunction(<function1>,IntegerType,Some(List(FloatType)))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val toInt = udf { v: Float => if (v > 0.5) 1 else 0 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predictions2 = List([userId: int, movieId: int ... 3 more fields], [userId: int, movieId: int ... 3 more fields], [userId: int, movieId: int ... 3 more fields], [userId: int, movieId: int ... 3 more fields], [userId: int, movieId: int ... 3 more fields], [userId: int, movieId: int ... 3 more fields], [userId: int, movieId: int ... 3 more fields], [userId: int, movieId: int ... 3 more fields])\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "List([userId: int, movieId: int ... 3 more fields], [userId: int, movieId: int ... 3 more fields], [userId: int, movieId: int ... 3 more fields], [userId: int, movieId: int ... 3 more fields], [userId: int, movieId: int ... 3 more fields], [userId: int, movieId: int ... 3 more fields], [userId: int, movieId: int ... 3 more fields], [userId: int, movieId: int ... 3 more fields])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val predictions2 = predictions.map { (df) => df.withColumn(\"prediction\", toInt(df(\"prediction\"))) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pred = [userId: int, movieId: int ... 3 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[userId: int, movieId: int ... 3 more fields]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val pred = predictions2(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scoreAndLabels = [_1: double, _2: double]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[_1: double, _2: double]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val scoreAndLabels = pred.select(\"rating\", \"prediction\").map { r => (r.getInt(0).toDouble, r.getInt(1).toDouble) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "metrics = org.apache.spark.mllib.evaluation.BinaryClassificationMetrics@6fe3151f\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.mllib.evaluation.BinaryClassificationMetrics@6fe3151f"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val metrics = new BinaryClassificationMetrics(scoreAndLabels.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5733430276500435"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.areaUnderROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Unknown Error\n",
       "Message: <console>:78: error: Unable to find encoder for type stored in a Dataset.  Primitive types (Int, String, etc) and Product types (case classes) are supported by importing spark.implicits._  Support for serializing other types will be added in future releases.\n",
       "       predictions2(0).map { r => r(0) }\n",
       "                           ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions2(0).map { r => case  } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluator = binEval_b72bec7f82f7\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "binEval_b72bec7f82f7"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val evaluator = new BinaryClassificationEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labelCol: label column name (default: label)\n",
       "metricName: metric name in evaluation (areaUnderROC|areaUnderPR) (default: areaUnderROC)\n",
       "rawPredictionCol: raw prediction (a.k.a. confidence) column name (default: rawPrediction)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.explainParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      " |-- ts: integer (nullable = true)\n",
      " |-- prediction: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions(0).printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
