{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.{min, max}\n",
    "import org.apache.spark.ml.recommendation.{ALS, ALSModel}\n",
    "import scala.util.Random\n",
    "import org.apache.spark.sql.functions.lit\n",
    "import org.apache.spark.sql.{Dataset, Row}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trainFile = ../datasets/movielens/ml-100k/ua.base\n",
       "testFile = ../datasets/movielens/ml-100k/ua.test\n",
       "columns = Array(user, movie, rating, ts)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[user, movie, rating, ts]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val trainFile = \"../datasets/movielens/ml-100k/ua.base\"\n",
    "val testFile = \"../datasets/movielens/ml-100k/ua.test\"\n",
    "val columns = Array(\"user\", \"movie\", \"rating\", \"ts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train = [user: int, movie: int ... 2 more fields]\n",
       "test = [user: int, movie: int ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[user: int, movie: int ... 2 more fields]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val train = spark.read.options(Map(\"header\" -> \"false\", \"inferSchema\" -> \"true\", \"delimiter\" -> \"\\t\")).csv(trainFile).toDF(columns: _*)\n",
    "val test = spark.read.options(Map(\"header\" -> \"false\", \"inferSchema\" -> \"true\", \"delimiter\" -> \"\\t\")).csv(testFile).toDF(columns: _*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------+---------+\n",
      "|user|movie|rating|       ts|\n",
      "+----+-----+------+---------+\n",
      "|   1|    1|     5|874965758|\n",
      "+----+-----+------+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------+---------+\n",
      "|user|movie|rating|       ts|\n",
      "+----+-----+------+---------+\n",
      "|   1|   20|     4|887431883|\n",
      "+----+-----+------+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stage 349:==================================================>     (9 + 1) / 10]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model = als_8c2d51206881\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "als_8c2d51206881"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val model = new ALS()\n",
    "    .setUserCol(\"user\")\n",
    "    .setItemCol(\"movie\")\n",
    "    .setRatingCol(\"rating\")\n",
    "    .setPredictionCol(\"prediction\")\n",
    "    .setImplicitPrefs(true)\n",
    "    .setRank(25)\n",
    "    .setNumUserBlocks(25)\n",
    "    .fit(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "als_5317ff46c06c"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.setColdStartStrategy(\"drop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recommendations = [user: int, recommendations: array<struct<movie:int,rating:float>>]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[user: int, recommendations: array<struct<movie:int,rating:float>>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val recommendations = model.recommendForAllUsers(1680)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(StructField(user,IntegerType,false), StructField(recommendations,ArrayType(StructType(StructField(movie,IntegerType,true), StructField(rating,FloatType,true)),true),true))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "moviesByUser = Map()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.collection.mutable\n",
    "val moviesByUser = mutable.Map[Int, List[Int]]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Broadcast(66)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sparkSession.sparkContext.broadcast(moviesByUser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "populateMoviesByUser = UserDefinedFunction(<function2>,ArrayType(IntegerType,false),Some(List(IntegerType, IntegerType)))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "UserDefinedFunction(<function2>,ArrayType(IntegerType,false),Some(List(IntegerType, IntegerType)))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.udf\n",
    "\n",
    "val populateMoviesByUser = udf { (user: Int, movie: Int) =>\n",
    "    println(user)\n",
    "    moviesByUser.update(user, movie :: moviesByUser.getOrElse(user, Nil))\n",
    "    moviesByUser.get(user).get\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "usersWithItems = [user: int, populated: array<int> ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[user: int, populated: array<int> ... 1 more field]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "val usersWithItems = train\n",
    "    .withColumn(\"populated\", populateMoviesByUser($\"user\", $\"movie\"))\n",
    "    .withColumn(\"countItems\", size($\"populated\"))\n",
    "    .sort(desc(\"countItems\"))\n",
    "    .select(\"user\", \"populated\", \"countItems\")\n",
    "    .dropDuplicates(\"user\")\n",
    "    .cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stage 355:====================================================>(169 + 1) / 170]+----+--------------------+----------+\n",
      "|user|           populated|countItems|\n",
      "+----+--------------------+----------+\n",
      "| 148|[1039, 1012, 1012...|       110|\n",
      "| 463|[1606, 1605, 1605...|       246|\n",
      "| 471|[1219, 946, 946, ...|        42|\n",
      "| 496|[1614, 1473, 1473...|       238|\n",
      "| 833|[1628, 1597, 1597...|       514|\n",
      "+----+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "usersWithItems.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision_at_k: (k: Int)Double\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def precision_at_k(k: Int): Double = {\n",
    "    val usersWithItemsMap = usersWithItems\n",
    "    .collect\n",
    "    .map { r => (r.getInt(0), r.getSeq[Int](1)) }.toMap[Int, Seq[Int]]\n",
    "\n",
    "    import org.apache.spark.sql.Row\n",
    "\n",
    "    case class UserPredictions(user: Int, predictions: Seq[Row])\n",
    "\n",
    "    import train.sparkSession.implicits._\n",
    "\n",
    "    val userRec = recommendations\n",
    "    .collect\n",
    "    .map {\n",
    "        r => UserPredictions(r.getInt(0), r.getAs[Seq[Row]](1) )\n",
    "    }.map { up: UserPredictions => \n",
    "        val predictions = up.predictions.map { r => (r.getInt(0), r.getFloat(1)) }\n",
    "        val topPredictions = predictions.flatMap { p =>\n",
    "            if (!usersWithItemsMap(up.user).contains(p._1))\n",
    "                Array(p)\n",
    "            else\n",
    "                None\n",
    "        }\n",
    "        .sortWith { (p1, p2) => p1._2 > p2._2 }\n",
    "        .take(k)\n",
    "        .map { p => p._1 }\n",
    "    \n",
    "        test\n",
    "            .filter($\"user\" equalTo up.user)\n",
    "            .filter($\"movie\" isin (topPredictions: _*) )\n",
    "            .count\n",
    "    }\n",
    "\n",
    "    var sum: Double = 0\n",
    "    userRec.take(10)\n",
    "    userRec.foreach { r => sum += r.toDouble / k }\n",
    "    sum / userRec.size\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stage 388:====================================================>(198 + 1) / 200]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2603393425238597"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_at_k(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stage 2303:===================================================>(198 + 1) / 200]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3295864262990433"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_at_k(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
